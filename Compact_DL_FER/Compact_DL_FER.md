### A Compact Deep Learning Model for Robust Facial Expression Recognition
2018 CVPR  
### 紧凑的深度学习模型，用于鲁棒的面部表情识别   
#### 摘要：
我们提出了一种基于框架的紧凑型面部表情识别框架，用于面部表情识别，相比于最新方法具有非常有竞争力的性能，同时使用的参数更少。提出的框架扩展到frame-to-sequence方法,通过利用有gated recurrent units（门控循环单元）的时间信息。此外，我们开发了一种光照增强方案，以缓解使用混合数据源训练深度网络时的过拟合问题。最后，我们使用提出的技术在一些公共数据集上证明性能的改进。  
#### 1.Introduction  
随着深度学习和人机交互的进步，从图像中了解人的情感变得越来越重要。人的情感表达方式有多种。研究表明，非姿势表达的分析必须依靠其他生理信号，例如温度变化和心率。遗憾的是，这些生理方法在实际中通常不可用或不可行，这使得研究结果仅限于实验室环境中。  
由于易于获取数据，基于视频的方法最常用于表情识别。具有严格限制的数据库通常用于面部表情识别的性能基准测试。传统的基于图像的面部表情识别方法采用了手工特征，比如LBP，BoW,HoG,SIFT,并且它们在几个数据库上都显示了相当不错的结果。此外，基于序列的方法还对时态情绪变化建模，从视频中提取出时间时间手工特征。   
最近，自然环境下的表情识别引起了广泛的关注。这种问题很具有挑战性，因为收集的面部图像通常是从互联网获取的在不同的照明条件和头部姿势下。诸如EmotioNet之类的研究还表明，将下载的图像用于训练集对于提高模型训练的通用性非常有用。这激励我们进一步研究表情识别任务如何从不受约束的环境中获取的面部图像数据集的模型训练中受益。  
在本文中，我们介绍了一种新的卷积神经网络（CNN）架构，以通过适当的深层设计来提高性能和泛化能力网络。标准数据库上的实验还显示所提出的CNN模型适用于面部具有紧凑网络参数的表情识别与相关的基于深度学习的模型相比。 此外，我们将几个不同类型的数据集包含到训练数据集以提高学习到的CNN模型的泛化能力。除此之外，我们研究了一种光照增强方案，以提高训练的CNN模型的鲁棒性。本文的主要贡献可以总结如下：  
•提出了一种用于面部表情识别的紧凑型CNN模型，以在识别精度和模型大小之间折衷。  
•在两个标准数据库上评估了我们的网络模型，并证明了所提出的方法优于最新方法。  
•收集了三个不同场景的数据集可用于评估跨域性能。  
•我们提出的“一站式（leave-one-set-out）”实验表明提议的光照增强策略减轻了模型训练中不同来源的图像的过度拟合问题。  
#### 2. Related Work  
BDBN表明，特征提取和选择与统一的增强型深度置信网络相结合可获得更好的性能。 STM-ExpLet 使用expressionlet-based 时空流形为表情视频剪辑建模。Exemplar-HMMs结合HMMs和SVMs在基于模型的相似性框架中。LOMo结合不同类型的complimentary特征，比如面部标志，LBP，SIFT，和几何特征，FER。  
在最近几年，自从CNN在许多计算机视觉任务中展现出其空前的能力以来，深度学习就变得非常流行。已经针对不同的图像分类任务提出了各种CNN模型。 但是，这些深度网络不适用于小型表情识别数据库。  
联合微调方法采用具有7个不同旋转角度的数据扩充策略，以获得14倍的数据。根据外观和几何特征训练两个不同的网络，并通过联合微调来组合预训练的网络。研究人员还表明，将CNN与递归神经网络（RNN）结合使用对于从视频中进行表情识别非常有效。  
最近，通过将从大规模人脸识别数据库中学习到的知识进行转移，峰值引导方法成功地将GoogLeNet应用于表情识别。 他们的结果还表明，基于图像的方法的准确性与基于序列的方法的准确性相当。  
#### 3. Proposed Framework   
所提出的深度学习方法的总体流程如图1所示。我们的框架由两个模块组成：人脸预处理和CNN分类。为了确保我们的框架可以扩展到不同的场景，我们不采用任何时间标准化
方法。  ![Fig1]()  
##### 3.1. Preprocessing   
我们首先根据IntraFace检测到的landmarks裁剪面部区域。这些landmarks可用于提取眉毛，眼睛，鼻子和嘴巴的轮廓。大crop可以保留更多信息，而小crop可以减少背景噪声或头部轮廓。裁剪后的图像尺寸 ![formula1]() 其中dv是the uppermost landmark point和the lowermost landmark point之间的距离, dh和the the leftmost landmark point和the rightmost landmark point之间的水平距离, α是用于控制面部区域大小的常量。对于所有实验，我们将α设置为1.05。  
一旦确定了裁剪的大小L，我们在鼻子的landmark上裁剪脸部区域中心，并获得适度的脸部图像以进行模型训练。将裁剪后的图像调整为固定尺寸120×120，然后将其发送到CNN分类器进行表情识别。  
##### 3.2. The CNN Model   
我们的CNN模型的架构如图2所示。 ![]() 模型由两个卷积和池化块，然后是两个全连接层，使用ReLU作为每个卷积层的激活函数。在全连接层后应用下采样以防止过拟合。注意，该模型仅将调整后的面部图像的中心96×96部分用作输入。有关模型训练的详细信息将在下一部分中描述。  
提议的CNN结构可以视为DTAN的改进版本。他们的实验已经表明，该简单模型可以在表情识别任务中取得良好的效果。为了进一步提高模型的识别能力，我们在最大池化之前堆叠了两个连续的卷积层。我们还使用了较大的卷积滤波器，从而使模型中的神经元具有更大的感受野。经过这种修改后，第一个完全连接层中每个神经元的感受野将变为36×36，约为输入96×96图像的14％，而原来的DTGAN为16×16，仅占输入大小为64×64的6%。  
另一个重要的修改是减少完全连接的神经元的数量。我们相信，只要我们对感受野进行适当的设计，就可以通过适度的模型大小来学习人脸的表情。本文后面的实验表明，合适的轻量级全连接网络不仅模型参数紧凑，而且对于面部表情识别也很准确。  
#### 3.3. The Frame-to-Sequence Model  

$$
\frac{\partial u^{(n)}}{\partial u^{(j)}}=\sum_{i : j \in P a\left(u^{(i)}\right)} \frac{\partial u^{(n)}}{\partial u^{(i)}} \frac{\partial u^{(i)}}{\partial u^{(j)}}
$$

$$
y_{i} \cong \widetilde{Y}_{i}=S\left(x_{i}^{1}, \ldots, x_{i}^{T} ; \theta\right)
$$


